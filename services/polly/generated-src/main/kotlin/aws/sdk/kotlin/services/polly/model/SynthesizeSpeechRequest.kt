// Code generated by smithy-kotlin-codegen. DO NOT EDIT!

package aws.sdk.kotlin.services.polly.model



class SynthesizeSpeechRequest private constructor(builder: BuilderImpl) {
    /**
     * Specifies the engine (standard or neural)
     * for Amazon Polly to use when processing input text for speech synthesis. For
     * information on Amazon Polly voices and which voices are available in
     * standard-only, NTTS-only, and both standard and NTTS formats, see <a href="https://docs.aws.amazon.com/polly/latest/dg/voicelist.html">Available Voices.
     * NTTS-only voices
     * When using NTTS-only voices such as Kevin (en-US), this parameter is
     * required and must be set to neural. If the engine is not
     * specified, or is set to standard, this will result in an
     * error.
     * Type: String
     * Valid Values: standard | neural
     * Required: Yes
     * Standard voices
     * For standard voices, this is not required; the engine parameter
     * defaults to standard. If the engine is not specified, or is
     * set to standard and an NTTS-only voice is selected, this will
     * result in an error.
     */
    val engine: Engine? = builder.engine
    /**
     * Optional language code for the Synthesize Speech request. This is only
     * necessary if using a bilingual voice, such as Aditi, which can be used for
     * either Indian English (en-IN) or Hindi (hi-IN).
     * If a bilingual voice is used and no language code is specified, Amazon Polly
     * uses the default language of the bilingual voice. The default language for
     * any voice is the one returned by the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation for the LanguageCode
     * parameter. For example, if no language code is specified, Aditi will use
     * Indian English rather than Hindi.
     */
    val languageCode: LanguageCode? = builder.languageCode
    /**
     * List of one or more pronunciation lexicon names you want the
     * service to apply during synthesis. Lexicons are applied only if the
     * language of the lexicon is the same as the language of the voice. For
     * information about storing lexicons, see <a href="https://docs.aws.amazon.com/polly/latest/dg/API_PutLexicon.html">PutLexicon.
     */
    val lexiconNames: List<String>? = builder.lexiconNames
    /**
     * The format in which the returned output will be encoded. For audio
     * stream, this will be mp3, ogg_vorbis, or pcm. For speech marks, this will
     * be json.
     * When pcm is used, the content returned is audio/pcm in a signed
     * 16-bit, 1 channel (mono), little-endian format.
     */
    val outputFormat: OutputFormat? = builder.outputFormat
    /**
     * The audio frequency specified in Hz.
     * The valid values for mp3 and ogg_vorbis are "8000", "16000", "22050",
     * and "24000". The default value for standard voices is "22050". The default
     * value for neural voices is "24000".
     * Valid values for pcm are "8000" and "16000" The default value is
     * "16000".
     */
    val sampleRate: String? = builder.sampleRate
    /**
     * The type of speech marks returned for the input text.
     */
    val speechMarkTypes: List<SpeechMarkType>? = builder.speechMarkTypes
    /**
     * Input text to synthesize. If you specify ssml as the
     * TextType, follow the SSML format for the input text.
     */
    val text: String? = builder.text
    /**
     * Specifies whether the input text is plain text or SSML. The
     * default value is plain text. For more information, see <a href="https://docs.aws.amazon.com/polly/latest/dg/ssml.html">Using
     * SSML.
     */
    val textType: TextType? = builder.textType
    /**
     * Voice ID to use for the synthesis. You can get a list of available
     * voice IDs by calling the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation.
     */
    val voiceId: VoiceId? = builder.voiceId

    companion object {
        @JvmStatic
        fun fluentBuilder(): FluentBuilder = BuilderImpl()

        internal fun builder(): DslBuilder = BuilderImpl()

        operator fun invoke(block: DslBuilder.() -> kotlin.Unit): SynthesizeSpeechRequest = BuilderImpl().apply(block).build()

    }

    override fun toString(): kotlin.String = buildString {
        append("SynthesizeSpeechRequest(")
        append("engine=$engine,")
        append("languageCode=$languageCode,")
        append("lexiconNames=$lexiconNames,")
        append("outputFormat=$outputFormat,")
        append("sampleRate=$sampleRate,")
        append("speechMarkTypes=$speechMarkTypes,")
        append("text=$text,")
        append("textType=$textType,")
        append("voiceId=$voiceId)")
    }

    override fun hashCode(): kotlin.Int {
        var result = engine?.hashCode() ?: 0
        result = 31 * result + (languageCode?.hashCode() ?: 0)
        result = 31 * result + (lexiconNames?.hashCode() ?: 0)
        result = 31 * result + (outputFormat?.hashCode() ?: 0)
        result = 31 * result + (sampleRate?.hashCode() ?: 0)
        result = 31 * result + (speechMarkTypes?.hashCode() ?: 0)
        result = 31 * result + (text?.hashCode() ?: 0)
        result = 31 * result + (textType?.hashCode() ?: 0)
        result = 31 * result + (voiceId?.hashCode() ?: 0)
        return result
    }

    override fun equals(other: kotlin.Any?): kotlin.Boolean {
        if (this === other) return true
        if (javaClass != other?.javaClass) return false

        other as SynthesizeSpeechRequest

        if (engine != other.engine) return false
        if (languageCode != other.languageCode) return false
        if (lexiconNames != other.lexiconNames) return false
        if (outputFormat != other.outputFormat) return false
        if (sampleRate != other.sampleRate) return false
        if (speechMarkTypes != other.speechMarkTypes) return false
        if (text != other.text) return false
        if (textType != other.textType) return false
        if (voiceId != other.voiceId) return false

        return true
    }

    fun copy(block: DslBuilder.() -> kotlin.Unit = {}): SynthesizeSpeechRequest = BuilderImpl(this).apply(block).build()

    interface FluentBuilder {
        fun build(): SynthesizeSpeechRequest
        /**
         * Specifies the engine (standard or neural)
         * for Amazon Polly to use when processing input text for speech synthesis. For
         * information on Amazon Polly voices and which voices are available in
         * standard-only, NTTS-only, and both standard and NTTS formats, see <a href="https://docs.aws.amazon.com/polly/latest/dg/voicelist.html">Available Voices.
         * NTTS-only voices
         * When using NTTS-only voices such as Kevin (en-US), this parameter is
         * required and must be set to neural. If the engine is not
         * specified, or is set to standard, this will result in an
         * error.
         * Type: String
         * Valid Values: standard | neural
         * Required: Yes
         * Standard voices
         * For standard voices, this is not required; the engine parameter
         * defaults to standard. If the engine is not specified, or is
         * set to standard and an NTTS-only voice is selected, this will
         * result in an error.
         */
        fun engine(engine: Engine): FluentBuilder
        /**
         * Optional language code for the Synthesize Speech request. This is only
         * necessary if using a bilingual voice, such as Aditi, which can be used for
         * either Indian English (en-IN) or Hindi (hi-IN).
         * If a bilingual voice is used and no language code is specified, Amazon Polly
         * uses the default language of the bilingual voice. The default language for
         * any voice is the one returned by the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation for the LanguageCode
         * parameter. For example, if no language code is specified, Aditi will use
         * Indian English rather than Hindi.
         */
        fun languageCode(languageCode: LanguageCode): FluentBuilder
        /**
         * List of one or more pronunciation lexicon names you want the
         * service to apply during synthesis. Lexicons are applied only if the
         * language of the lexicon is the same as the language of the voice. For
         * information about storing lexicons, see <a href="https://docs.aws.amazon.com/polly/latest/dg/API_PutLexicon.html">PutLexicon.
         */
        fun lexiconNames(lexiconNames: List<String>): FluentBuilder
        /**
         * The format in which the returned output will be encoded. For audio
         * stream, this will be mp3, ogg_vorbis, or pcm. For speech marks, this will
         * be json.
         * When pcm is used, the content returned is audio/pcm in a signed
         * 16-bit, 1 channel (mono), little-endian format.
         */
        fun outputFormat(outputFormat: OutputFormat): FluentBuilder
        /**
         * The audio frequency specified in Hz.
         * The valid values for mp3 and ogg_vorbis are "8000", "16000", "22050",
         * and "24000". The default value for standard voices is "22050". The default
         * value for neural voices is "24000".
         * Valid values for pcm are "8000" and "16000" The default value is
         * "16000".
         */
        fun sampleRate(sampleRate: String): FluentBuilder
        /**
         * The type of speech marks returned for the input text.
         */
        fun speechMarkTypes(speechMarkTypes: List<SpeechMarkType>): FluentBuilder
        /**
         * Input text to synthesize. If you specify ssml as the
         * TextType, follow the SSML format for the input text.
         */
        fun text(text: String): FluentBuilder
        /**
         * Specifies whether the input text is plain text or SSML. The
         * default value is plain text. For more information, see <a href="https://docs.aws.amazon.com/polly/latest/dg/ssml.html">Using
         * SSML.
         */
        fun textType(textType: TextType): FluentBuilder
        /**
         * Voice ID to use for the synthesis. You can get a list of available
         * voice IDs by calling the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation.
         */
        fun voiceId(voiceId: VoiceId): FluentBuilder
    }

    interface DslBuilder {
        /**
         * Specifies the engine (standard or neural)
         * for Amazon Polly to use when processing input text for speech synthesis. For
         * information on Amazon Polly voices and which voices are available in
         * standard-only, NTTS-only, and both standard and NTTS formats, see <a href="https://docs.aws.amazon.com/polly/latest/dg/voicelist.html">Available Voices.
         * NTTS-only voices
         * When using NTTS-only voices such as Kevin (en-US), this parameter is
         * required and must be set to neural. If the engine is not
         * specified, or is set to standard, this will result in an
         * error.
         * Type: String
         * Valid Values: standard | neural
         * Required: Yes
         * Standard voices
         * For standard voices, this is not required; the engine parameter
         * defaults to standard. If the engine is not specified, or is
         * set to standard and an NTTS-only voice is selected, this will
         * result in an error.
         */
        var engine: Engine?
        /**
         * Optional language code for the Synthesize Speech request. This is only
         * necessary if using a bilingual voice, such as Aditi, which can be used for
         * either Indian English (en-IN) or Hindi (hi-IN).
         * If a bilingual voice is used and no language code is specified, Amazon Polly
         * uses the default language of the bilingual voice. The default language for
         * any voice is the one returned by the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation for the LanguageCode
         * parameter. For example, if no language code is specified, Aditi will use
         * Indian English rather than Hindi.
         */
        var languageCode: LanguageCode?
        /**
         * List of one or more pronunciation lexicon names you want the
         * service to apply during synthesis. Lexicons are applied only if the
         * language of the lexicon is the same as the language of the voice. For
         * information about storing lexicons, see <a href="https://docs.aws.amazon.com/polly/latest/dg/API_PutLexicon.html">PutLexicon.
         */
        var lexiconNames: List<String>?
        /**
         * The format in which the returned output will be encoded. For audio
         * stream, this will be mp3, ogg_vorbis, or pcm. For speech marks, this will
         * be json.
         * When pcm is used, the content returned is audio/pcm in a signed
         * 16-bit, 1 channel (mono), little-endian format.
         */
        var outputFormat: OutputFormat?
        /**
         * The audio frequency specified in Hz.
         * The valid values for mp3 and ogg_vorbis are "8000", "16000", "22050",
         * and "24000". The default value for standard voices is "22050". The default
         * value for neural voices is "24000".
         * Valid values for pcm are "8000" and "16000" The default value is
         * "16000".
         */
        var sampleRate: String?
        /**
         * The type of speech marks returned for the input text.
         */
        var speechMarkTypes: List<SpeechMarkType>?
        /**
         * Input text to synthesize. If you specify ssml as the
         * TextType, follow the SSML format for the input text.
         */
        var text: String?
        /**
         * Specifies whether the input text is plain text or SSML. The
         * default value is plain text. For more information, see <a href="https://docs.aws.amazon.com/polly/latest/dg/ssml.html">Using
         * SSML.
         */
        var textType: TextType?
        /**
         * Voice ID to use for the synthesis. You can get a list of available
         * voice IDs by calling the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices operation.
         */
        var voiceId: VoiceId?

        fun build(): SynthesizeSpeechRequest
    }

    private class BuilderImpl() : FluentBuilder, DslBuilder {
        override var engine: Engine? = null
        override var languageCode: LanguageCode? = null
        override var lexiconNames: List<String>? = null
        override var outputFormat: OutputFormat? = null
        override var sampleRate: String? = null
        override var speechMarkTypes: List<SpeechMarkType>? = null
        override var text: String? = null
        override var textType: TextType? = null
        override var voiceId: VoiceId? = null

        constructor(x: SynthesizeSpeechRequest) : this() {
            this.engine = x.engine
            this.languageCode = x.languageCode
            this.lexiconNames = x.lexiconNames
            this.outputFormat = x.outputFormat
            this.sampleRate = x.sampleRate
            this.speechMarkTypes = x.speechMarkTypes
            this.text = x.text
            this.textType = x.textType
            this.voiceId = x.voiceId
        }

        override fun build(): SynthesizeSpeechRequest = SynthesizeSpeechRequest(this)
        override fun engine(engine: Engine): FluentBuilder = apply { this.engine = engine }
        override fun languageCode(languageCode: LanguageCode): FluentBuilder = apply { this.languageCode = languageCode }
        override fun lexiconNames(lexiconNames: List<String>): FluentBuilder = apply { this.lexiconNames = lexiconNames }
        override fun outputFormat(outputFormat: OutputFormat): FluentBuilder = apply { this.outputFormat = outputFormat }
        override fun sampleRate(sampleRate: String): FluentBuilder = apply { this.sampleRate = sampleRate }
        override fun speechMarkTypes(speechMarkTypes: List<SpeechMarkType>): FluentBuilder = apply { this.speechMarkTypes = speechMarkTypes }
        override fun text(text: String): FluentBuilder = apply { this.text = text }
        override fun textType(textType: TextType): FluentBuilder = apply { this.textType = textType }
        override fun voiceId(voiceId: VoiceId): FluentBuilder = apply { this.voiceId = voiceId }
    }
}
